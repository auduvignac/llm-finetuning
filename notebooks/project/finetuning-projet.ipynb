{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66150ed9",
   "metadata": {},
   "source": [
    "# Classification de textes avec les Transformers\n",
    "\n",
    "<p align=\"center\">\n",
    "  <a href=\"https://colab.research.google.com/github/auduvignac/llm-finetuning/blob/main/notebooks/project/finetuning-projet.ipynb\" target=\"_blank\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Ouvrir dans Google Colab\"/>\n",
    "  </a>\n",
    "</p>\n",
    "\n",
    "\n",
    "\n",
    "Ce projet porte sur une tâche de **classification de textes** appliquée au **jeu de données IMDB** (analyse de sentiments ou *sentimental analysis*).  \n",
    "Ce travail s'appuiera sur les **architectures de type encodeur**, en particulier l’un des modèles les plus connus : **BERT** (et sa variante légère **DistilBERT**).\n",
    "\n",
    "## Présentation\n",
    "\n",
    "Le projet consiste à utiliser la librairie `datasets` pour le chargement des données et les `tokenizers` pour le prétraitement des textes.\n",
    "\n",
    "La librairie **Transformers** propose une API simple pour utiliser des modèles pré-entraînés tels que **BERT** ou **GPT**. Elle facilite leur téléchargement, leur ré-entraînement et leur intégration, tout en réduisant les coûts de calcul et en restant compatible avec **PyTorch, TensorFlow et JAX**.\n",
    "\n",
    "## Objectif du projet\n",
    "\n",
    "Dans le cadre de ce projet, l’expérimentation portera sur la librairie **Hugging Face** afin de :\n",
    "- Charger et adapter un modèle de type **BERT** à une tâche de classification de textes ; \n",
    "- Évaluer ses performances sur le dataset **IMDB** ;\n",
    "- Analyser les résultats et discuter des choix réalisés (modèle, preprocessing, paramètres, etc.).\n",
    "\n",
    "Le travail sera guidé par les interrogations suivantes :\n",
    "\n",
    "- Bien que tous ces modèles reposent sur l’architecture **Transformer**, quelles en sont les spécificités ?\n",
    "- Quel format d’entrée est attendu par le modèle ?\n",
    "- Quels types de sorties génère-t-il ?\n",
    "- Le modèle peut-il être utilisé tel quel ou doit-il être adapté à la tâche considérée ?\n",
    "\n",
    "Ces questions constituent une part essentielle du travail quotidien d’un chercheur en NLP et seront examinées dans le cadre de ce projet de *fine-tuning*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "powershell"
    }
   },
   "outputs": [],
   "source": [
    "!wget -q https://raw.githubusercontent.com/auduvignac/llm-finetuning/refs/heads/main/setup_env.py -O setup_env.py\n",
    "%run setup_env.py"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
